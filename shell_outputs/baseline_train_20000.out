[2020-04-08 03:10:30,282 INFO]  Starting process pid: 11782  
[2020-04-08 03:10:30,287 INFO]  Starting process pid: 11783  
[2020-04-08 03:10:31,641 INFO] Namespace(accum_count=5, alpha=0.6, batch_size=140, beam_size=5, bert_data_path='../baseline_input_data/cnndm', beta1=0.9, beta2=0.999, block_trigram=True, dec_dropout=0.2, dec_ff_size=2048, dec_heads=8, dec_hidden_size=768, dec_layers=6, enc_dropout=0.2, enc_ff_size=512, enc_hidden_size=512, enc_layers=6, encoder='bert', ext_dropout=0.2, ext_ff_size=2048, ext_heads=8, ext_hidden_size=768, ext_layers=2, finetune_bert=True, generator_shard_size=32, gpu_ranks=[0, 1], label_smoothing=0.1, large=False, load_from_extractive='../models/author_ext_model/bertext_cnndm_transformer.pt', log_file='../baseline_output_logs/log_baseline_bert_cnndm', lr=1, lr_bert=0.0002, lr_dec=0.1, max_grad_norm=0, max_length=150, max_pos=512, max_tgt_len=140, min_length=15, mode='train', model_path='../baseline_model', optim='adam', param_init=0, param_init_glorot=True, recall_eval=False, report_every=50, report_rouge=True, result_path='../results/cnndm', save_checkpoint_steps=2000, seed=666, sep_optim=True, share_emb=False, task='abs', temp_dir='../temp', test_all=False, test_batch_size=200, test_from='', test_start_from=-1, train_from='../baseline_model/model_step_18000.pt', train_steps=20000, use_bert_emb=True, use_interval=True, visible_gpus='0,1', warmup_steps=8000, warmup_steps_bert=10000, warmup_steps_dec=5000, world_size=2)
[2020-04-08 03:10:31,642 INFO] Device ID 0
[2020-04-08 03:10:31,642 INFO] Device cuda
[2020-04-08 03:10:33,092 INFO] Loading checkpoint from ../baseline_model/model_step_18000.pt
[2020-04-08 03:10:34,582 INFO] Loading bert from extractive model ../models/author_ext_model/bertext_cnndm_transformer.pt
[2020-04-08 03:10:35,578 INFO] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at ../temp/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.8f56353af4a709bf5ff0fbc915d8f5b42bfff892cbb6ac98c3c45f481a03c685
[2020-04-08 03:10:35,579 INFO] Model config {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 2,
  "output_attentions": false,
  "output_hidden_states": false,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

[2020-04-08 03:10:35,655 INFO] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at ../temp/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.8f56353af4a709bf5ff0fbc915d8f5b42bfff892cbb6ac98c3c45f481a03c685
[2020-04-08 03:10:35,657 INFO] Model config {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 2,
  "output_attentions": false,
  "output_hidden_states": false,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

[2020-04-08 03:10:35,703 INFO] loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at ../temp/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157
[2020-04-08 03:10:35,790 INFO] loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at ../temp/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157
[2020-04-08 03:10:44,626 INFO] AbsSummarizer(
  (bert): Bert(
    (model): BertModel(
      (embeddings): BertEmbeddings(
        (word_embeddings): Embedding(30522, 768, padding_idx=0)
        (position_embeddings): Embedding(512, 768)
        (token_type_embeddings): Embedding(2, 768)
        (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1)
            )
          )
          (1): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1)
            )
          )
          (2): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1)
            )
          )
          (3): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1)
            )
          )
          (4): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1)
            )
          )
          (5): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1)
            )
          )
          (6): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1)
            )
          )
          (7): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1)
            )
          )
          (8): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1)
            )
          )
          (9): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1)
            )
          )
          (10): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1)
            )
          )
          (11): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1)
            )
          )
        )
      )
      (pooler): BertPooler(
        (dense): Linear(in_features=768, out_features=768, bias=True)
        (activation): Tanh()
      )
    )
  )
  (decoder): TransformerDecoder(
    (embeddings): Embedding(30522, 768, padding_idx=0)
    (pos_emb): PositionalEncoding(
      (dropout): Dropout(p=0.2)
    )
    (transformer_layers): ModuleList(
      (0): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=768, out_features=768, bias=True)
          (linear_values): Linear(in_features=768, out_features=768, bias=True)
          (linear_query): Linear(in_features=768, out_features=768, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.2)
          (final_linear): Linear(in_features=768, out_features=768, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=768, out_features=768, bias=True)
          (linear_values): Linear(in_features=768, out_features=768, bias=True)
          (linear_query): Linear(in_features=768, out_features=768, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.2)
          (final_linear): Linear(in_features=768, out_features=768, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=768, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=768, bias=True)
          (layer_norm): LayerNorm(torch.Size([768]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.2)
          (dropout_2): Dropout(p=0.2)
        )
        (layer_norm_1): LayerNorm(torch.Size([768]), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm(torch.Size([768]), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.2)
      )
      (1): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=768, out_features=768, bias=True)
          (linear_values): Linear(in_features=768, out_features=768, bias=True)
          (linear_query): Linear(in_features=768, out_features=768, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.2)
          (final_linear): Linear(in_features=768, out_features=768, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=768, out_features=768, bias=True)
          (linear_values): Linear(in_features=768, out_features=768, bias=True)
          (linear_query): Linear(in_features=768, out_features=768, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.2)
          (final_linear): Linear(in_features=768, out_features=768, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=768, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=768, bias=True)
          (layer_norm): LayerNorm(torch.Size([768]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.2)
          (dropout_2): Dropout(p=0.2)
        )
        (layer_norm_1): LayerNorm(torch.Size([768]), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm(torch.Size([768]), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.2)
      )
      (2): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=768, out_features=768, bias=True)
          (linear_values): Linear(in_features=768, out_features=768, bias=True)
          (linear_query): Linear(in_features=768, out_features=768, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.2)
          (final_linear): Linear(in_features=768, out_features=768, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=768, out_features=768, bias=True)
          (linear_values): Linear(in_features=768, out_features=768, bias=True)
          (linear_query): Linear(in_features=768, out_features=768, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.2)
          (final_linear): Linear(in_features=768, out_features=768, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=768, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=768, bias=True)
          (layer_norm): LayerNorm(torch.Size([768]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.2)
          (dropout_2): Dropout(p=0.2)
        )
        (layer_norm_1): LayerNorm(torch.Size([768]), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm(torch.Size([768]), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.2)
      )
      (3): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=768, out_features=768, bias=True)
          (linear_values): Linear(in_features=768, out_features=768, bias=True)
          (linear_query): Linear(in_features=768, out_features=768, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.2)
          (final_linear): Linear(in_features=768, out_features=768, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=768, out_features=768, bias=True)
          (linear_values): Linear(in_features=768, out_features=768, bias=True)
          (linear_query): Linear(in_features=768, out_features=768, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.2)
          (final_linear): Linear(in_features=768, out_features=768, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=768, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=768, bias=True)
          (layer_norm): LayerNorm(torch.Size([768]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.2)
          (dropout_2): Dropout(p=0.2)
        )
        (layer_norm_1): LayerNorm(torch.Size([768]), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm(torch.Size([768]), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.2)
      )
      (4): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=768, out_features=768, bias=True)
          (linear_values): Linear(in_features=768, out_features=768, bias=True)
          (linear_query): Linear(in_features=768, out_features=768, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.2)
          (final_linear): Linear(in_features=768, out_features=768, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=768, out_features=768, bias=True)
          (linear_values): Linear(in_features=768, out_features=768, bias=True)
          (linear_query): Linear(in_features=768, out_features=768, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.2)
          (final_linear): Linear(in_features=768, out_features=768, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=768, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=768, bias=True)
          (layer_norm): LayerNorm(torch.Size([768]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.2)
          (dropout_2): Dropout(p=0.2)
        )
        (layer_norm_1): LayerNorm(torch.Size([768]), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm(torch.Size([768]), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.2)
      )
      (5): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=768, out_features=768, bias=True)
          (linear_values): Linear(in_features=768, out_features=768, bias=True)
          (linear_query): Linear(in_features=768, out_features=768, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.2)
          (final_linear): Linear(in_features=768, out_features=768, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=768, out_features=768, bias=True)
          (linear_values): Linear(in_features=768, out_features=768, bias=True)
          (linear_query): Linear(in_features=768, out_features=768, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.2)
          (final_linear): Linear(in_features=768, out_features=768, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=768, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=768, bias=True)
          (layer_norm): LayerNorm(torch.Size([768]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.2)
          (dropout_2): Dropout(p=0.2)
        )
        (layer_norm_1): LayerNorm(torch.Size([768]), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm(torch.Size([768]), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.2)
      )
    )
    (layer_norm): LayerNorm(torch.Size([768]), eps=1e-06, elementwise_affine=True)
  )
  (generator): Sequential(
    (0): Linear(in_features=768, out_features=30522, bias=True)
    (1): LogSoftmax()
  )
)
[2020-04-08 03:10:44,759 INFO] loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at ../temp/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
[2020-04-08 03:10:44,864 INFO] * number of parameters: 180222522
[2020-04-08 03:10:44,864 INFO] Start training...
[2020-04-08 03:10:45,018 INFO] Loading train dataset from ../baseline_input_data/cnndm.train.9.bert.pt, number of examples: 1999
[2020-04-08 03:10:45,121 INFO] loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at ../temp/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
[0, 1]
gpu_rank 1
gpu_rank 1
[2020-04-08 03:11:38,639 INFO] Step 18050/20000; acc:  59.03; ppl:  5.12; xent: 1.63; lr: 0.00000149;   0/850 tok/s;     54 sec
[0, 1]
gpu_rank 0
gpu_rank 0
[2020-04-08 03:12:29,444 INFO] Step 18100/20000; acc:  61.22; ppl:  4.91; xent: 1.59; lr: 0.00000149;   0/893 tok/s;    104 sec
[2020-04-08 03:12:53,983 INFO] Loading train dataset from ../baseline_input_data/cnndm.train.6.bert.pt, number of examples: 2001
[2020-04-08 03:13:21,973 INFO] Step 18150/20000; acc:  52.07; ppl:  8.38; xent: 2.13; lr: 0.00000148;   0/856 tok/s;    157 sec
[2020-04-08 03:14:14,957 INFO] Step 18200/20000; acc:  53.14; ppl:  7.57; xent: 2.02; lr: 0.00000148;   0/1110 tok/s;    210 sec
[2020-04-08 03:15:03,585 INFO] Loading train dataset from ../baseline_input_data/cnndm.train.10.bert.pt, number of examples: 2001
[2020-04-08 03:15:07,777 INFO] Step 18250/20000; acc:  51.10; ppl:  9.63; xent: 2.26; lr: 0.00000148;   0/913 tok/s;    263 sec
[2020-04-08 03:16:00,561 INFO] Step 18300/20000; acc:  57.20; ppl:  7.02; xent: 1.95; lr: 0.00000148;   0/978 tok/s;    316 sec
[2020-04-08 03:16:52,789 INFO] Step 18350/20000; acc:  54.82; ppl:  7.76; xent: 2.05; lr: 0.00000148;   0/956 tok/s;    368 sec
[2020-04-08 03:17:11,542 INFO] Loading train dataset from ../baseline_input_data/cnndm.train.11.bert.pt, number of examples: 1999
[2020-04-08 03:17:45,595 INFO] Step 18400/20000; acc:  60.84; ppl:  5.10; xent: 1.63; lr: 0.00000147;   0/1257 tok/s;    421 sec
[2020-04-08 03:18:38,161 INFO] Step 18450/20000; acc:  58.11; ppl:  6.22; xent: 1.83; lr: 0.00000147;   0/947 tok/s;    473 sec
[2020-04-08 03:19:20,734 INFO] Loading train dataset from ../baseline_input_data/cnndm.train.1.bert.pt, number of examples: 2001
[2020-04-08 03:19:31,109 INFO] Step 18500/20000; acc:  49.51; ppl: 10.48; xent: 2.35; lr: 0.00000147;   0/922 tok/s;    526 sec
[2020-04-08 03:20:23,268 INFO] Step 18550/20000; acc:  58.25; ppl:  7.03; xent: 1.95; lr: 0.00000147;   0/995 tok/s;    578 sec
[2020-04-08 03:21:15,708 INFO] Step 18600/20000; acc:  54.03; ppl:  7.05; xent: 1.95; lr: 0.00000147;   0/1223 tok/s;    631 sec
[2020-04-08 03:21:30,807 INFO] Loading train dataset from ../baseline_input_data/cnndm.train.7.bert.pt, number of examples: 2001
[2020-04-08 03:22:09,770 INFO] Step 18650/20000; acc:  55.62; ppl:  7.79; xent: 2.05; lr: 0.00000146;   0/1010 tok/s;    685 sec
[2020-04-08 03:23:01,727 INFO] Step 18700/20000; acc:  51.75; ppl:  8.52; xent: 2.14; lr: 0.00000146;   0/1006 tok/s;    737 sec
[2020-04-08 03:23:41,030 INFO] Loading train dataset from ../baseline_input_data/cnndm.train.5.bert.pt, number of examples: 2001
[2020-04-08 03:23:54,176 INFO] Step 18750/20000; acc:  58.40; ppl:  6.23; xent: 1.83; lr: 0.00000146;   0/1164 tok/s;    789 sec
[2020-04-08 03:24:47,961 INFO] Step 18800/20000; acc:  55.92; ppl:  6.68; xent: 1.90; lr: 0.00000146;   0/951 tok/s;    843 sec
[2020-04-08 03:25:39,785 INFO] Step 18850/20000; acc:  56.89; ppl:  6.17; xent: 1.82; lr: 0.00000146;   0/1135 tok/s;    895 sec
[2020-04-08 03:25:48,182 INFO] Loading train dataset from ../baseline_input_data/cnndm.train.13.bert.pt, number of examples: 2001
[2020-04-08 03:26:32,377 INFO] Step 18900/20000; acc:  53.27; ppl:  8.82; xent: 2.18; lr: 0.00000145;   0/1023 tok/s;    947 sec
[2020-04-08 03:27:25,339 INFO] Step 18950/20000; acc:  62.72; ppl:  5.55; xent: 1.71; lr: 0.00000145;   0/1004 tok/s;   1000 sec
[2020-04-08 03:27:55,892 INFO] Loading train dataset from ../baseline_input_data/cnndm.train.0.bert.pt, number of examples: 2001
[2020-04-08 03:28:16,479 INFO] Step 19000/20000; acc:  53.09; ppl:  7.86; xent: 2.06; lr: 0.00000145;   0/892 tok/s;   1051 sec
[2020-04-08 03:29:08,620 INFO] Step 19050/20000; acc:  46.12; ppl: 10.82; xent: 2.38; lr: 0.00000145;   0/1130 tok/s;   1104 sec
[2020-04-08 03:30:00,558 INFO] Step 19100/20000; acc:  57.76; ppl:  6.40; xent: 1.86; lr: 0.00000145;   0/1033 tok/s;   1156 sec
[2020-04-08 03:30:03,931 INFO] Loading train dataset from ../baseline_input_data/cnndm.train.4.bert.pt, number of examples: 2001
[2020-04-08 03:30:53,142 INFO] Step 19150/20000; acc:  64.90; ppl:  4.92; xent: 1.59; lr: 0.00000145;   0/1091 tok/s;   1208 sec
[2020-04-08 03:31:45,162 INFO] Step 19200/20000; acc:  55.88; ppl:  6.54; xent: 1.88; lr: 0.00000144;   0/1041 tok/s;   1260 sec
[2020-04-08 03:32:11,200 INFO] Loading train dataset from ../baseline_input_data/cnndm.train.12.bert.pt, number of examples: 2001
[2020-04-08 03:32:36,689 INFO] Step 19250/20000; acc:  60.05; ppl:  6.42; xent: 1.86; lr: 0.00000144;   0/1112 tok/s;   1312 sec
[2020-04-08 03:33:29,332 INFO] Step 19300/20000; acc:  58.00; ppl:  6.06; xent: 1.80; lr: 0.00000144;   0/1009 tok/s;   1364 sec
[2020-04-08 03:34:20,502 INFO] Step 19350/20000; acc:  54.04; ppl:  7.88; xent: 2.06; lr: 0.00000144;   0/865 tok/s;   1415 sec
[2020-04-08 03:34:20,818 INFO] Loading train dataset from ../baseline_input_data/cnndm.train.8.bert.pt, number of examples: 2000
[2020-04-08 03:35:13,357 INFO] Step 19400/20000; acc:  54.15; ppl:  7.45; xent: 2.01; lr: 0.00000144;   0/1126 tok/s;   1468 sec
[2020-04-08 03:36:05,742 INFO] Step 19450/20000; acc:  53.06; ppl:  7.59; xent: 2.03; lr: 0.00000143;   0/1002 tok/s;   1521 sec
[2020-04-08 03:36:27,821 INFO] Loading train dataset from ../baseline_input_data/cnndm.train.2.bert.pt, number of examples: 2001
[2020-04-08 03:36:58,402 INFO] Step 19500/20000; acc:  50.29; ppl:  8.57; xent: 2.15; lr: 0.00000143;   0/893 tok/s;   1573 sec
[2020-04-08 03:37:50,315 INFO] Step 19550/20000; acc:  54.71; ppl:  7.34; xent: 1.99; lr: 0.00000143;   0/1072 tok/s;   1625 sec
[2020-04-08 03:38:35,855 INFO] Loading train dataset from ../baseline_input_data/cnndm.train.3.bert.pt, number of examples: 2001
[2020-04-08 03:38:42,445 INFO] Step 19600/20000; acc:  52.97; ppl:  8.70; xent: 2.16; lr: 0.00000143;   0/939 tok/s;   1677 sec
[2020-04-08 03:39:34,992 INFO] Step 19650/20000; acc:  54.72; ppl:  7.94; xent: 2.07; lr: 0.00000143;   0/878 tok/s;   1730 sec
[2020-04-08 03:40:26,765 INFO] Step 19700/20000; acc:  55.04; ppl:  7.50; xent: 2.01; lr: 0.00000142;   0/819 tok/s;   1782 sec
[2020-04-08 03:40:44,610 INFO] Loading train dataset from ../baseline_input_data/cnndm.train.9.bert.pt, number of examples: 1999
[2020-04-08 03:41:17,760 INFO] Step 19750/20000; acc:  58.94; ppl:  5.64; xent: 1.73; lr: 0.00000142;   0/1104 tok/s;   1833 sec
[2020-04-08 03:42:10,377 INFO] Step 19800/20000; acc:  65.49; ppl:  4.15; xent: 1.42; lr: 0.00000142;   0/1023 tok/s;   1885 sec
[2020-04-08 03:42:53,284 INFO] Loading train dataset from ../baseline_input_data/cnndm.train.13.bert.pt, number of examples: 2001
[2020-04-08 03:43:02,819 INFO] Step 19850/20000; acc:  57.78; ppl:  6.10; xent: 1.81; lr: 0.00000142;   0/819 tok/s;   1938 sec
[2020-04-08 03:43:54,892 INFO] Step 19900/20000; acc:  61.57; ppl:  5.19; xent: 1.65; lr: 0.00000142;   0/811 tok/s;   1990 sec
[2020-04-08 03:44:46,561 INFO] Step 19950/20000; acc:  57.62; ppl:  5.73; xent: 1.75; lr: 0.00000142;   0/975 tok/s;   2042 sec
[2020-04-08 03:45:01,691 INFO] Loading train dataset from ../baseline_input_data/cnndm.train.11.bert.pt, number of examples: 1999
[2020-04-08 03:45:39,048 INFO] Step 20000/20000; acc:  64.78; ppl:  4.37; xent: 1.47; lr: 0.00000141;   0/950 tok/s;   2094 sec
[2020-04-08 03:45:39,051 INFO] Saving checkpoint ../baseline_model/model_step_20000.pt
[2020-04-08 03:46:01,281 INFO] Loading train dataset from ../baseline_input_data/cnndm.train.4.bert.pt, number of examples: 2001
baseline_train_20000.sh: error reading input file: Stale file handle
